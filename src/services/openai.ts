import { MetaData } from '../metadata';

/**
 * OpenAI æ¶ˆæ¯æ¥å£
 */
export interface OpenAIMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

/**
 * OpenAI å“åº”æ¥å£
 */
export interface OpenAIResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}
const startTime = Date.now();
let totalContentGenerated = 0;
const processingTaskIds = new Set<string>();

const printReport = () => {
  const speed = (totalContentGenerated / ((Date.now() - startTime) / 1000)).toFixed(2);
  const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
  console.error(
    `â³ AI Processing output speed=${speed} total=${totalContentGenerated} elapsed=${elapsed} s tasks=${processingTaskIds.size}`
  );
  // å–å‰ 5 ä¸ªæ­£åœ¨å¤„ç†çš„ä»»åŠ¡ID
  let i = 5;
  for (const id of processingTaskIds) {
    if (i-- <= 0) break;
    console.error(` - processing task: ${id}`);
  }
};

let isReporting = false;
const setupReport = async () => {
  if (isReporting) return;
  isReporting = true;
  while (processingTaskIds.size > 0) {
    try {
      printReport();
    } catch (e) {}
    await new Promise(resolve => setTimeout(resolve, 1000));
  }
  isReporting = false;
};

/**
 * ä½¿ç”¨ OpenAI API è¡¥å…¨æ¶ˆæ¯
 * @param messages æ¶ˆæ¯æ•°ç»„
 * @param options å¯é€‰é…ç½®
 * @returns Promise<OpenAIResponse> è¿”å›å®Œæ•´çš„OpenAIå“åº”
 */
export const completeMessages = async (
  messages: OpenAIMessage[],
  options?: {
    /**
     * å¯é€‰çš„ä»»åŠ¡IDï¼Œç”¨äºæ ‡è¯†è¯·æ±‚ï¼Œä¾¿äºæ—¥å¿—è®°å½•
     */
    task_id?: string;
    response_format?: { type: 'json_object' | 'text' };
  }
): Promise<OpenAIResponse> => {
  try {
    if (options?.task_id) {
      processingTaskIds.add(options.task_id);
      setupReport();
    }
    // ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    const apiKey = process.env.OPENAI_API_KEY || '';
    const baseUrl = process.env.OPENAI_BASE_URL || 'https://api.openai.com/v1';
    const model = process.env.OPENAI_MODEL || 'gpt-3.5-turbo';
    const max_tokens = process.env.OPENAI_MAX_TOKENS ? +process.env.OPENAI_MAX_TOKENS : undefined; // ä¸å¡«å°±ä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼

    if (!apiKey) {
      throw new Error('OPENAI_API_KEY environment variable is not set');
    }

    let finishReason: string | null = null;
    let responseId: string | null = null;
    let responseModel: string | null = null;
    let responseCreated: number | null = null;
    let usage: OpenAIResponse['usage'] | null = null;

    const requestBody: any = {
      model,
      messages,
      temperature: 0, // æ€»æ˜¯è®¾ç½®ä¸º 0ï¼Œæå–å†…å®¹ä¸éœ€è¦éšæœºæ€§
      stream: true, // å¯ç”¨æµå¼å“åº”
      max_tokens, // å¯é€‰çš„æœ€å¤§ token æ•°é‡
    };

    // æ·»åŠ å¯é€‰çš„response_format
    if (options?.response_format) {
      requestBody.response_format = options.response_format;
    }

    // æ‰“å°è¯·æ±‚ä¿¡æ¯ (for debug)
    // if (MetaData.options.verbose) {
    //   for (const msg of messages) {
    //     console.info(`ğŸ’¬ [${msg.role}] ${msg.content}`);
    //   }
    // }

    const response = await fetch(`${baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify(requestBody),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`OpenAI API error (${response.status}): ${errorText}`);
    }

    // å¤„ç†æµå¼å“åº”
    const reader = response.body?.getReader();
    if (!reader) {
      throw new Error('No response body reader available');
    }

    const decoder = new TextDecoder();
    let buffer = '';

    let content = '';

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      buffer = lines.pop() || ''; // ä¿ç•™æœªå®Œæˆçš„è¡Œ

      for (const line of lines) {
        const trimmedLine = line.trim();
        if (!trimmedLine || trimmedLine === 'data: [DONE]') continue;

        if (trimmedLine.startsWith('data: ')) {
          const jsonStr = trimmedLine.slice(6);
          try {
            const chunk = JSON.parse(jsonStr);

            // æ”¶é›†å…ƒæ•°æ®
            if (chunk.id) responseId = chunk.id;
            if (chunk.model) responseModel = chunk.model;
            if (chunk.created) responseCreated = chunk.created;

            // å¤„ç† choices
            if (chunk.choices && Array.isArray(chunk.choices)) {
              for (const choice of chunk.choices) {
                if (choice.delta?.content) {
                  totalContentGenerated += choice.delta.content.length;
                  content += choice.delta.content;
                }
                if (choice.finish_reason) {
                  finishReason = choice.finish_reason;
                }
              }
            }

            // å¤„ç† usage
            if (chunk.usage) {
              usage = chunk.usage;
            }
          } catch (error) {
            console.warn('Failed to parse SSE chunk:', jsonStr, error);
          }
        }
      }
    }

    // ç¡®ä¿æ‰€æœ‰å‰©ä½™æ•°æ®è¢«è§£ç 
    if (buffer) {
      buffer += decoder.decode();
      // å¯ä»¥å°è¯•è§£æå‰©ä½™æ•°æ®ï¼Œä½†é€šå¸¸ä¸ä¼šæœ‰å®Œæ•´æ•°æ®
    }

    // æ„å»ºæœ€ç»ˆçš„å“åº”å¯¹è±¡
    const finalResponse: OpenAIResponse = {
      id: responseId || `chatcmpl-${Date.now()}`,
      object: 'chat.completion',
      created: responseCreated || Math.floor(Date.now() / 1000),
      model: responseModel || model,
      choices: [
        {
          index: 0,
          message: {
            role: 'assistant',
            content: content,
          },
          finish_reason: finishReason || 'stop',
        },
      ],
      usage: usage || {
        prompt_tokens: 0,
        completion_tokens: 0,
        total_tokens: 0,
      },
    };

    if (MetaData.options.verbose) {
      console.info('ğŸ¤– AI Token Usages', finalResponse.usage);
    }

    // éªŒè¯å“åº”
    if (!finalResponse.choices?.[0]?.message?.content?.trim()) {
      throw new Error('Empty response from OpenAI API');
    }

    return finalResponse;
  } catch (error) {
    console.error('âŒ Failed to call OpenAI API:', error);
    throw error;
  } finally {
    if (options?.task_id) {
      processingTaskIds.delete(options.task_id);
    }
  }
};
