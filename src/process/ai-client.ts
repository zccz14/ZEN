import { extractMetadataFromMarkdown } from '../ai/extractMetadataFromMarkdown';
import { AIMetadata, FileInfo } from '../types';
import { cacheMetadata, getCachedMetadata, logTokenUsage } from './ai-utils';

/**
 * è°ƒç”¨ AI æ¨¡å‹æå–æ–‡æ¡£ metadata
 * @param content æ–‡æ¡£å†…å®¹
 * @param filePath æ–‡ä»¶è·¯å¾„
 * @param config AI é…ç½®ï¼ˆå¯é€‰ï¼‰
 * @returns æå–çš„ metadataï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› null
 */
export async function callAIForMetadata(
  content: string,
  filePath: string
): Promise<AIMetadata | null> {
  // API key æ£€æŸ¥ç°åœ¨åœ¨ services/openai.ts ä¸­å¤„ç†
  // å¦‚æœ API key ä¸å­˜åœ¨ï¼ŒcompleteMessages å‡½æ•°ä¼šæŠ›å‡ºé”™è¯¯

  try {
    const metadata = await extractMetadataFromMarkdown(content, filePath);

    // æ‰“å° tokens ä½¿ç”¨æƒ…å†µ
    if (metadata.tokens_used) {
      logTokenUsage(filePath, metadata.tokens_used);
    }

    return metadata;
  } catch (error) {
    console.error(`âŒ Failed to extract AI metadata for ${filePath}:`, error);
    return null;
  }
}

/**
 * æ‰¹é‡è°ƒç”¨ AI å¤„ç†æ–‡ä»¶
 * @param files æ–‡ä»¶æ•°ç»„ï¼ŒåŒ…å«å†…å®¹ã€è·¯å¾„å’Œå“ˆå¸Œå€¼
 * @param config AI é…ç½®ï¼ˆå¯é€‰ï¼‰
 * @returns æ–‡ä»¶è·¯å¾„åˆ° metadata çš„æ˜ å°„
 */
async function batchCallAI(
  files: Array<{ content: string; path: string; hash: string }>
): Promise<Map<string, AIMetadata>> {
  const results = new Map<string, AIMetadata>();

  // API key æ£€æŸ¥ç°åœ¨åœ¨ services/openai.ts ä¸­å¤„ç†
  // å¦‚æœ API key ä¸å­˜åœ¨ï¼ŒcompleteMessages å‡½æ•°ä¼šæŠ›å‡ºé”™è¯¯

  console.log(`ğŸ¤– Processing ${files.length} files with AI...`);

  for (const file of files) {
    try {
      // æ£€æŸ¥ç¼“å­˜
      const cachedMetadata = await getCachedMetadata(file.hash, file.path);
      if (cachedMetadata) {
        results.set(file.path, cachedMetadata);
        continue;
      }

      // è°ƒç”¨ AI æå– metadata
      const metadata = await callAIForMetadata(file.content, file.path);
      if (metadata) {
        results.set(file.path, metadata);

        // ç¼“å­˜ç»“æœ
        await cacheMetadata(file.hash, file.path, metadata);
      }
    } catch (error) {
      console.error(`âŒ Failed to process file ${file.path}:`, error);
    }
  }

  return results;
}

/**
 * æ‰¹é‡å¤„ç†æ–‡ä»¶
 * @param files æ–‡ä»¶ä¿¡æ¯æ•°ç»„
 * @param config AI é…ç½®ï¼ˆå¯é€‰ï¼‰
 */
export async function batchProcessAI(files: FileInfo[]): Promise<Map<string, any>> {
  console.log(`ğŸ¤– Processing ${files.length} files with AI...`);

  const filesToProcess = files.filter(file => file.hash && !file.aiMetadata);
  if (filesToProcess.length === 0) {
    console.log('ğŸ“š All files already have AI metadata or no files to process');
    return new Map();
  }

  // å‡†å¤‡æ•°æ®
  const fileData = filesToProcess.map(file => ({
    content: file.content,
    path: file.path,
    hash: file.hash!,
  }));

  // æ‰¹é‡å¤„ç†
  const results = await batchCallAI(fileData);

  // æ›´æ–°æ–‡ä»¶ä¿¡æ¯
  for (const file of filesToProcess) {
    const metadata = results.get(file.path);
    if (metadata) {
      file.aiMetadata = metadata;
    }
  }

  console.log(`âœ… AI processing completed for ${results.size} files`);
  return results;
}
