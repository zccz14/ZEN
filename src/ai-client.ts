import { AIMetadata } from './types';
import { AIService, AIConfig } from './ai-service';

/**
 * OpenAI å…¼å®¹ API å“åº”æ¥å£
 */
interface OpenAIResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

/**
 * AI å®¢æˆ·ç«¯ç±» - ä½¿ç”¨ fetch è°ƒç”¨ OpenAI å…¼å®¹ API
 */
export class AIClient {
  private aiService: AIService;

  constructor(aiService: AIService) {
    this.aiService = aiService;
  }

  /**
   * è°ƒç”¨ AI æ¨¡å‹æå–æ–‡æ¡£ metadata
   */
  async extractMetadata(content: string, filePath: string): Promise<AIMetadata | null> {
    const config = this.aiService.getConfig();

    if (!config.apiKey) {
      console.log(`âš ï¸ API key not configured for: ${filePath}`);
      return null;
    }

    try {
      console.log(`ğŸ¤– Extracting AI metadata for: ${filePath}`);

      const prompt = this.buildMetadataPrompt(content);
      const response = await this.callOpenAIAPI(prompt, config);

      if (!response) {
        console.warn(`âš ï¸ Failed to extract metadata for: ${filePath}`);
        return null;
      }

      const metadata = this.parseMetadataResponse(response.choices[0].message.content);

      // æ·»åŠ  tokens ä½¿ç”¨æƒ…å†µ
      metadata.tokens_used = {
        prompt: response.usage.prompt_tokens,
        completion: response.usage.completion_tokens,
        total: response.usage.total_tokens,
      };

      // æ‰“å° tokens ä½¿ç”¨æƒ…å†µ
      this.aiService.logTokenUsage(filePath, metadata.tokens_used);

      return metadata;
    } catch (error) {
      console.error(`âŒ Failed to extract AI metadata for ${filePath}:`, error);
      return null;
    }
  }

  /**
   * æ„å»ºæå– metadata çš„ prompt
   */
  private buildMetadataPrompt(content: string): string {
    // é™åˆ¶å†…å®¹é•¿åº¦ä»¥é¿å… token è¶…é™
    const maxContentLength = 8000;
    const truncatedContent =
      content.length > maxContentLength
        ? content.substring(0, maxContentLength) + '... [å†…å®¹å·²æˆªæ–­]'
        : content;

    return `è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯å¹¶è¿”å› JSON æ ¼å¼ï¼š

æ–‡æ¡£å†…å®¹ï¼š
"""
${truncatedContent}
"""

è¯·æå–ï¼š
1. title: æ–‡æ¡£çš„æ ‡é¢˜ï¼ˆç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡ 20 ä¸ªå­—ï¼‰
2. summary: æ–‡æ¡£æ‘˜è¦ï¼ˆæ§åˆ¶åœ¨ 100 å­—ä»¥å†…ï¼Œæ¦‚æ‹¬ä¸»è¦å†…å®¹ï¼‰
3. tags: å…³é”®è¯åˆ—è¡¨ï¼ˆ3-8 ä¸ªå…³é”®è¯ï¼Œä½¿ç”¨ä¸­æ–‡æˆ–è‹±æ–‡ï¼‰
4. inferred_date: æ–‡æ¡£ä¸­éšå«çš„åˆ›å»ºæ—¥æœŸï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼Œæ²¡æœ‰å°±ç•™ç©ºå­—ç¬¦ä¸²ï¼‰
5. inferred_lang: æ–‡æ¡£ä½¿ç”¨çš„è¯­è¨€ä»£ç ï¼ˆä¾‹å¦‚ï¼šzh-Hans è¡¨ç¤ºç®€ä½“ä¸­æ–‡ï¼Œen-US è¡¨ç¤ºç¾å¼è‹±è¯­ï¼‰

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬ï¼š
{
  "title": "æ–‡æ¡£æ ‡é¢˜",
  "summary": "æ–‡æ¡£æ‘˜è¦...",
  "tags": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
  "inferred_date": "2023-01-01",
  "inferred_lang": "zh-Hans"
}`;
  }

  /**
   * è°ƒç”¨ OpenAI å…¼å®¹ API
   */
  private async callOpenAIAPI(prompt: string, config: AIConfig): Promise<OpenAIResponse | null> {
    try {
      const response = await fetch(`${config.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${config.apiKey}`,
        },
        body: JSON.stringify({
          model: config.model,
          messages: [
            {
              role: 'system',
              content:
                'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»æ–‡æ¡£ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„ JSON æ ¼å¼è¿”å›ç»“æœã€‚',
            },
            {
              role: 'user',
              content: prompt,
            },
          ],
          temperature: config.temperature,
          max_tokens: config.maxTokens,
          response_format: { type: 'json_object' },
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`âŒ OpenAI API error (${response.status}):`, errorText);
        return null;
      }

      const data: OpenAIResponse = await response.json();
      return data;
    } catch (error) {
      console.error('âŒ Failed to call OpenAI API:', error);
      return null;
    }
  }

  /**
   * è§£æ AI è¿”å›çš„ metadata
   */
  private parseMetadataResponse(responseContent: string): AIMetadata {
    try {
      const metadata = JSON.parse(responseContent);

      // éªŒè¯å’Œæ¸…ç†æ•°æ®
      return {
        title: metadata.title?.trim() || 'æœªå‘½åæ–‡æ¡£',
        summary: metadata.summary?.trim() || '',
        tags: Array.isArray(metadata.tags)
          ? metadata.tags.map((tag: string) => tag.trim()).filter(Boolean)
          : [],
        inferred_date: metadata.inferred_date?.trim() || undefined,
        inferred_lang: metadata.inferred_lang?.trim() || 'zh-Hans',
      };
    } catch (error) {
      console.error('âŒ Failed to parse AI response:', error, 'Response:', responseContent);

      // è¿”å›é»˜è®¤å€¼
      return {
        title: 'è§£æå¤±è´¥',
        summary: 'AI å“åº”è§£æå¤±è´¥',
        tags: ['error'],
        inferred_lang: 'zh-Hans',
      };
    }
  }

  /**
   * æ‰¹é‡å¤„ç†æ–‡ä»¶
   */
  async processFiles(
    files: Array<{ content: string; path: string; hash: string }>
  ): Promise<Map<string, AIMetadata>> {
    const results = new Map<string, AIMetadata>();
    const config = this.aiService.getConfig();

    if (!config.apiKey) {
      console.log('âš ï¸ API key not configured');
      return results;
    }

    console.log(`ğŸ¤– Processing ${files.length} files with AI...`);

    for (const file of files) {
      try {
        // æ£€æŸ¥ç¼“å­˜
        const cachedMetadata = await this.aiService.getCachedMetadata(file.hash, file.path);
        if (cachedMetadata) {
          results.set(file.path, cachedMetadata);
          continue;
        }

        // è°ƒç”¨ AI æå– metadata
        const metadata = await this.extractMetadata(file.content, file.path);
        if (metadata) {
          results.set(file.path, metadata);

          // ç¼“å­˜ç»“æœ
          await this.aiService.cacheMetadata(file.hash, file.path, metadata);
        }
      } catch (error) {
        console.error(`âŒ Failed to process file ${file.path}:`, error);
      }
    }

    return results;
  }
}
