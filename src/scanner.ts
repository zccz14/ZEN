import { FileInfo } from './types';
import * as fs from 'fs/promises';
import * as path from 'path';
import { GitIgnoreProcessor } from './gitignore';

export interface ScanOptions {
  srcDir: string;
  scanDir?: string;
  includePattern?: string;
  excludePattern?: string;
  verbose?: boolean;
}

export interface ScanResult {
  files: FileInfo[];
  scanDir: string;
  timestamp: number;
}

export class FileScanner {
  /**
   * æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ Markdown æ–‡ä»¶
   */
  async scan(options: ScanOptions): Promise<ScanResult> {
    const { srcDir, scanDir, verbose = false } = options;
    const files: FileInfo[] = [];

    // åˆ›å»º GitIgnoreProcessor å¹¶åŠ è½½ .gitignore æ–‡ä»¶
    const gitignoreProcessor = new GitIgnoreProcessor(srcDir);
    await gitignoreProcessor.loadFromFile();

    // æ‰«æç›®å½•
    await this.scanDirectory(srcDir, srcDir, files, gitignoreProcessor, verbose, srcDir);

    // ç¡®å®šæ‰«æç»“æœç›®å½•
    const finalScanDir = scanDir || path.join(srcDir, '.zen', 'src');

    // ç¡®ä¿æ‰«æç›®å½•å­˜åœ¨
    await fs.mkdir(finalScanDir, { recursive: true });

    // ä¿å­˜æ‰«æç»“æœ
    const scanResult: ScanResult = {
      files,
      scanDir: finalScanDir,
      timestamp: Date.now(),
    };

    await this.saveScanResult(scanResult, finalScanDir);

    if (verbose) {
      console.log(`ğŸ“„ Scanned ${files.length} Markdown files`);
      console.log(`ğŸ“ Scan results saved to: ${finalScanDir}`);
    }

    return scanResult;
  }

  /**
   * é€’å½’æ‰«æç›®å½•
   */
  private async scanDirectory(
    currentPath: string,
    baseDir: string,
    files: FileInfo[],
    gitignoreProcessor: GitIgnoreProcessor,
    verbose: boolean,
    rootDir: string
  ): Promise<void> {
    const entries = await fs.readdir(currentPath, { withFileTypes: true });

    for (const entry of entries) {
      const fullPath = path.join(currentPath, entry.name);

      // æ£€æŸ¥æ˜¯å¦åº”è¯¥è¢« .gitignore å¿½ç•¥
      if (gitignoreProcessor.shouldIgnore(fullPath)) {
        if (verbose) console.log(`  Ignoring (gitignore): ${fullPath}`);
        continue;
      }

      // å¿½ç•¥ .zen ç›®å½•ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
      if (entry.name === '.zen') {
        if (verbose) console.log(`  Ignoring (.zen): ${fullPath}`);
        continue;
      }

      if (entry.isDirectory()) {
        await this.scanDirectory(fullPath, baseDir, files, gitignoreProcessor, verbose, rootDir);
      } else if (entry.isFile() && entry.name.endsWith('.md')) {
        try {
          const content = await fs.readFile(fullPath, 'utf-8');
          const relativePath = path.relative(rootDir, fullPath);
          const ext = path.extname(entry.name);
          const name = path.basename(entry.name, ext);

          files.push({
            path: fullPath,
            relativePath,
            name,
            ext,
            content,
          });

          if (verbose) console.log(`  Found: ${relativePath}`);
        } catch (error) {
          console.error(`âŒ Failed to read file ${fullPath}:`, error);
        }
      }
    }
  }

  /**
   * ä¿å­˜æ‰«æç»“æœåˆ°æ–‡ä»¶
   */
  private async saveScanResult(scanResult: ScanResult, scanDir: string): Promise<void> {
    // ä¿å­˜æ–‡ä»¶åˆ—è¡¨
    const filesJson = JSON.stringify(
      scanResult.files.map(file => ({
        path: file.path,
        relativePath: file.relativePath,
        name: file.name,
        ext: file.ext,
      })),
      null,
      2
    );

    await fs.writeFile(path.join(scanDir, 'files.json'), filesJson, 'utf-8');

    // ä¿å­˜æ‰«æå…ƒæ•°æ®
    const metadata = {
      timestamp: scanResult.timestamp,
      scanDir: scanResult.scanDir,
      fileCount: scanResult.files.length,
    };

    await fs.writeFile(
      path.join(scanDir, 'metadata.json'),
      JSON.stringify(metadata, null, 2),
      'utf-8'
    );

    // å¤åˆ¶æ–‡ä»¶å†…å®¹åˆ°æ‰«æç›®å½•ï¼ˆå¯é€‰ï¼Œç”¨äºå¢é‡æ„å»ºï¼‰
    await this.copyFilesToScanDir(scanResult.files, scanDir);
  }

  /**
   * å°†æ–‡ä»¶å¤åˆ¶åˆ°æ‰«æç›®å½•
   */
  private async copyFilesToScanDir(files: FileInfo[], scanDir: string): Promise<void> {
    for (const file of files) {
      try {
        const targetPath = path.join(scanDir, file.relativePath);
        const targetDir = path.dirname(targetPath);

        // ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        await fs.mkdir(targetDir, { recursive: true });

        // å¤åˆ¶æ–‡ä»¶å†…å®¹
        await fs.writeFile(targetPath, file.content, 'utf-8');
      } catch (error) {
        console.error(`âŒ Failed to copy file ${file.path}:`, error);
      }
    }
  }

  /**
   * ä»æ‰«æç›®å½•åŠ è½½æ‰«æç»“æœ
   */
  async loadScanResult(scanDir: string): Promise<ScanResult> {
    try {
      // åŠ è½½å…ƒæ•°æ®
      const metadataContent = await fs.readFile(path.join(scanDir, 'metadata.json'), 'utf-8');
      const metadata = JSON.parse(metadataContent);

      // åŠ è½½æ–‡ä»¶åˆ—è¡¨
      const filesContent = await fs.readFile(path.join(scanDir, 'files.json'), 'utf-8');
      const fileEntries = JSON.parse(filesContent);

      // ä»æ‰«æç›®å½•è¯»å–æ–‡ä»¶å†…å®¹
      const files: FileInfo[] = [];
      for (const entry of fileEntries) {
        try {
          const content = await fs.readFile(path.join(scanDir, entry.relativePath), 'utf-8');

          files.push({
            ...entry,
            content,
          });
        } catch (error) {
          console.error(`âŒ Failed to load file ${entry.relativePath}:`, error);
        }
      }

      return {
        files,
        scanDir,
        timestamp: metadata.timestamp,
      };
    } catch (error) {
      throw new Error(`Failed to load scan result from ${scanDir}: ${error}`);
    }
  }

  /**
   * æ¸…ç†æ‰«æç›®å½•
   */
  async cleanScanDir(scanDir: string): Promise<void> {
    try {
      await fs.rm(scanDir, { recursive: true, force: true });
      console.log(`ğŸ§¹ Cleaned scan directory: ${scanDir}`);
    } catch (error) {
      console.error(`âŒ Failed to clean scan directory:`, error);
    }
  }
}
